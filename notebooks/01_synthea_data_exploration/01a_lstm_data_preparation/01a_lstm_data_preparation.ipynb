{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Data Preparation: From Patient Sequences to Model Inputs\n",
    "\n",
    "This notebook demonstrates how to prepare visit-grouped patient sequences for the LSTM baseline model.\n",
    "\n",
    "**Prediction Objective:** Binary classification - predicting if a patient has diabetes based on their EHR sequence.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll walk through the complete data transformation pipeline:\n",
    "\n",
    "1. **Load processed sequences** from the main exploration notebook\n",
    "2. **Encode sequences** to integer IDs using vocabulary\n",
    "3. **Create labels** for prediction task (diabetes detection)\n",
    "4. **Prepare batches** with proper padding and masking\n",
    "5. **Visualize data shapes** at each transformation step\n",
    "6. **Create LSTM-ready tensors** for model input\n",
    "\n",
    "See `data_shape_transformations.md` for detailed documentation of all shape changes.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Import ehrsequencing package\n",
    "from ehrsequencing.data.adapters import SyntheaAdapter\n",
    "from ehrsequencing.data.visit_grouper import VisitGrouper\n",
    "from ehrsequencing.data.sequence_builder import PatientSequenceBuilder\n",
    "from ehrsequencing.models import create_lstm_baseline\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Load and Prepare Data\n",
    "\n",
    "We'll start by loading Synthea data and creating patient sequences (same as notebook 01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded Synthea data from: /Users/pleiadian53/work/loinc-predictor/data/synthea/all_cohorts\n"
     ]
    }
   ],
   "source": [
    "# Path to Synthea data\n",
    "data_path = Path.home() / 'work' / 'loinc-predictor' / 'data' / 'synthea' / 'all_cohorts'\n",
    "\n",
    "# Initialize adapter\n",
    "adapter = SyntheaAdapter(data_path=str(data_path))\n",
    "\n",
    "print(f\"âœ… Loaded Synthea data from: {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 patients\n",
      "\n",
      "ðŸ“Š Data Shape: List[PatientInfo] with length 50\n"
     ]
    }
   ],
   "source": [
    "# Load patients (using more for better examples)\n",
    "patients = adapter.load_patients(limit=50)\n",
    "patient_ids = [p.patient_id for p in patients]\n",
    "\n",
    "print(f\"Loaded {len(patients)} patients\")\n",
    "print(f\"\\nðŸ“Š Data Shape: List[PatientInfo] with length {len(patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VisitGrouper initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize visit grouper\n",
    "visit_grouper = VisitGrouper(\n",
    "    strategy='hybrid',\n",
    "    time_window_hours=24,\n",
    "    preserve_code_types=True\n",
    ")\n",
    "\n",
    "print(\"âœ… VisitGrouper initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50 patients...\n",
      "\n",
      "âœ… Grouped visits for 50 patients\n",
      "\n",
      "ðŸ“Š Data Shape: Dict[str, List[Visit]]\n",
      "   - Keys: 50 patient IDs\n",
      "   - Values: Lists of Visit objects\n",
      "   - Total visits: 3037\n"
     ]
    }
   ],
   "source": [
    "# Load events and group into visits\n",
    "print(f\"Processing {len(patient_ids)} patients...\")\n",
    "\n",
    "patient_visits = {}\n",
    "for patient_id in patient_ids:\n",
    "    events = adapter.load_events(patient_ids=[patient_id])\n",
    "    visits = visit_grouper.group_events(events, patient_id=patient_id)\n",
    "    patient_visits[patient_id] = visits\n",
    "\n",
    "print(f\"\\nâœ… Grouped visits for {len(patient_visits)} patients\")\n",
    "print(f\"\\nðŸ“Š Data Shape: Dict[str, List[Visit]]\")\n",
    "print(f\"   - Keys: {len(patient_visits)} patient IDs\")\n",
    "print(f\"   - Values: Lists of Visit objects\")\n",
    "print(f\"   - Total visits: {sum(len(v) for v in patient_visits.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Build Patient Sequences\n",
    "\n",
    "Transform visit groups into structured patient sequences with vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PatientSequenceBuilder initialized\n",
      "   Max visits per sequence: 50\n",
      "   Max codes per visit: 100\n"
     ]
    }
   ],
   "source": [
    "# Initialize sequence builder\n",
    "sequence_builder = PatientSequenceBuilder(\n",
    "    vocab=None,\n",
    "    max_visits=50,\n",
    "    max_codes_per_visit=100,\n",
    "    use_semantic_order=True\n",
    ")\n",
    "\n",
    "print(\"âœ… PatientSequenceBuilder initialized\")\n",
    "print(f\"   Max visits per sequence: 50\")\n",
    "print(f\"   Max codes per visit: 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary...\n",
      "\n",
      "âœ… Vocabulary built\n",
      "   Vocabulary size: 659\n",
      "   Special tokens: [PAD]=0, [UNK]=1, [MASK]=2, [CLS]=3, [SEP]=4\n",
      "\n",
      "ðŸ“Š Data Shape: Dict[str, int]\n",
      "   - Medical code â†’ Integer ID mapping\n",
      "   - Example: [('[PAD]', 0), ('[UNK]', 1), ('[MASK]', 2), ('[CLS]', 3), ('[SEP]', 4)]\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary from all patient visits\n",
    "print(\"Building vocabulary...\")\n",
    "vocab = sequence_builder.build_vocabulary(list(patient_visits.values()), min_frequency=1)\n",
    "\n",
    "print(f\"\\nâœ… Vocabulary built\")\n",
    "print(f\"   Vocabulary size: {len(vocab)}\")\n",
    "print(f\"   Special tokens: [PAD]=0, [UNK]=1, [MASK]=2, [CLS]=3, [SEP]=4\")\n",
    "print(f\"\\nðŸ“Š Data Shape: Dict[str, int]\")\n",
    "print(f\"   - Medical code â†’ Integer ID mapping\")\n",
    "print(f\"   - Example: {list(vocab.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building patient sequences...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'patient_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Build patient sequences\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding patient sequences...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m sequences \u001b[38;5;241m=\u001b[39m \u001b[43msequence_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_visits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_visits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Built \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sequences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Filtered out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(patient_visits)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(sequences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m patients (< 2 visits)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/ehr-sequencing/src/ehrsequencing/data/sequence_builder.py:166\u001b[0m, in \u001b[0;36mPatientSequenceBuilder.build_sequences\u001b[0;34m(self, patient_visits, min_visits)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Assume all visits in the list belong to the same patient\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m patient_id \u001b[38;5;241m=\u001b[39m \u001b[43mvisits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatient_id\u001b[49m\n\u001b[1;32m    168\u001b[0m sequence \u001b[38;5;241m=\u001b[39m PatientSequence(\n\u001b[1;32m    169\u001b[0m     patient_id\u001b[38;5;241m=\u001b[39mpatient_id,\n\u001b[1;32m    170\u001b[0m     visits\u001b[38;5;241m=\u001b[39mvisits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     }\n\u001b[1;32m    176\u001b[0m )\n\u001b[1;32m    177\u001b[0m sequences\u001b[38;5;241m.\u001b[39mappend(sequence)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'patient_id'"
     ]
    }
   ],
   "source": [
    "# Build patient sequences\n",
    "print(\"Building patient sequences...\")\n",
    "sequences = sequence_builder.build_sequences(list(patient_visits.values()), min_visits=2)\n",
    "\n",
    "print(f\"\\nâœ… Built {len(sequences)} sequences\")\n",
    "print(f\"   Filtered out: {len(patient_visits) - len(sequences)} patients (< 2 visits)\")\n",
    "print(f\"\\nðŸ“Š Data Shape: List[PatientSequence]\")\n",
    "print(f\"   - Length: {len(sequences)}\")\n",
    "print(f\"   - Each PatientSequence contains:\")\n",
    "print(f\"     â€¢ patient_id: str\")\n",
    "print(f\"     â€¢ visits: List[Visit]\")\n",
    "print(f\"     â€¢ sequence_length: int\")\n",
    "print(f\"     â€¢ metadata: Optional[Dict]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Examine Raw Patient Sequence\n",
    "\n",
    "Let's look at a patient sequence before encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample sequence\n",
    "sample_seq = sequences[0]\n",
    "\n",
    "print(\"Sample Patient Sequence (Before Encoding):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Patient ID: {sample_seq.patient_id}\")\n",
    "print(f\"Number of visits: {sample_seq.sequence_length}\")\n",
    "print(f\"\\nðŸ“Š Data Shape:\")\n",
    "print(f\"   - Type: PatientSequence dataclass\")\n",
    "print(f\"   - visits: List[Visit] with length {len(sample_seq.visits)}\")\n",
    "\n",
    "# Show first 3 visits\n",
    "print(f\"\\nFirst 3 visits:\")\n",
    "for i, visit in enumerate(sample_seq.visits[:3]):\n",
    "    print(f\"\\n  Visit {i+1}:\")\n",
    "    print(f\"    Timestamp: {visit.timestamp}\")\n",
    "    print(f\"    Number of codes: {visit.num_codes()}\")\n",
    "    print(f\"    Code types: {list(visit.codes_by_type.keys())}\")\n",
    "    \n",
    "    # Show some actual codes\n",
    "    all_codes = visit.get_all_codes()\n",
    "    print(f\"    Sample codes (first 5): {all_codes[:5]}\")\n",
    "    print(f\"    ðŸ“Š Shape: List[str] with length {len(all_codes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Encode Sequences for LSTM\n",
    "\n",
    "Transform string codes to integer IDs with proper padding and masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sample sequence\n",
    "encoded = sequence_builder.encode_sequence(sample_seq, return_tensors=False)\n",
    "\n",
    "print(\"Encoded Sequence (LSTM-Ready Format):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Patient ID: {encoded['patient_id']}\")\n",
    "print(f\"Sequence length: {encoded['sequence_length']} visits\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Data Shapes After Encoding:\")\n",
    "print(f\"   visit_codes: {np.array(encoded['visit_codes']).shape}\")\n",
    "print(f\"      â†’ [num_visits={len(encoded['visit_codes'])}, max_codes_per_visit={len(encoded['visit_codes'][0])}]\")\n",
    "print(f\"      â†’ Type: List[List[int]]\")\n",
    "print(f\"\\n   visit_mask: {np.array(encoded['visit_mask']).shape}\")\n",
    "print(f\"      â†’ [num_visits={len(encoded['visit_mask'])}, max_codes_per_visit={len(encoded['visit_mask'][0])}]\")\n",
    "print(f\"      â†’ Type: List[List[int]] (1=real code, 0=padding)\")\n",
    "print(f\"\\n   sequence_mask: {np.array(encoded['sequence_mask']).shape}\")\n",
    "print(f\"      â†’ [num_visits={len(encoded['sequence_mask'])}]\")\n",
    "print(f\"      â†’ Type: List[int] (1=real visit, 0=padding)\")\n",
    "print(f\"\\n   time_deltas: {np.array(encoded['time_deltas']).shape}\")\n",
    "print(f\"      â†’ [num_visits-1={len(encoded['time_deltas'])}]\")\n",
    "print(f\"      â†’ Type: List[float] (days between consecutive visits)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show actual encoded values for first visit\n",
    "print(\"First Visit - Detailed View:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "first_visit_codes = encoded['visit_codes'][0]\n",
    "first_visit_mask = encoded['visit_mask'][0]\n",
    "\n",
    "# Count real vs padded codes\n",
    "num_real_codes = sum(first_visit_mask)\n",
    "num_padding = len(first_visit_mask) - num_real_codes\n",
    "\n",
    "print(f\"Real codes: {num_real_codes}\")\n",
    "print(f\"Padding: {num_padding}\")\n",
    "print(f\"\\nFirst 10 code IDs: {first_visit_codes[:10]}\")\n",
    "print(f\"First 10 mask values: {first_visit_mask[:10]}\")\n",
    "print(f\"\\nLast 10 code IDs (should be padding): {first_visit_codes[-10:]}\")\n",
    "print(f\"Last 10 mask values (should be 0): {first_visit_mask[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Create Labels for Prediction Task\n",
    "\n",
    "**Task:** Binary classification - predict if patient has diabetes.\n",
    "\n",
    "We'll use SNOMED-CT codes for diabetes diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define diabetes-related codes (SNOMED-CT)\n",
    "diabetes_codes = {\n",
    "    '44054006',   # Type 2 diabetes mellitus\n",
    "    '46635009',   # Type 1 diabetes mellitus\n",
    "    '73211009',   # Diabetes mellitus\n",
    "    '11687002',   # Gestational diabetes\n",
    "    '190330002',  # Diabetes mellitus without complication\n",
    "    '190331003',  # Diabetes mellitus with complication\n",
    "}\n",
    "\n",
    "print(f\"Diabetes codes: {diabetes_codes}\")\n",
    "print(f\"Number of codes: {len(diabetes_codes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for all sequences\n",
    "def has_diabetes(sequence):\n",
    "    \"\"\"Check if patient has diabetes based on their visit codes.\"\"\"\n",
    "    for visit in sequence.visits:\n",
    "        all_codes = visit.get_all_codes()\n",
    "        if any(code in diabetes_codes for code in all_codes):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Create dataset with labels\n",
    "dataset_items = []\n",
    "for seq in sequences:\n",
    "    encoded = sequence_builder.encode_sequence(seq, return_tensors=False)\n",
    "    label = 1 if has_diabetes(seq) else 0\n",
    "    \n",
    "    dataset_items.append({\n",
    "        'patient_id': seq.patient_id,\n",
    "        'visit_codes': encoded['visit_codes'],\n",
    "        'visit_mask': encoded['visit_mask'],\n",
    "        'sequence_mask': encoded['sequence_mask'],\n",
    "        'time_deltas': encoded['time_deltas'],\n",
    "        'label': label\n",
    "    })\n",
    "\n",
    "print(f\"\\nâœ… Created {len(dataset_items)} labeled sequences\")\n",
    "print(f\"\\nðŸ“Š Dataset Item Shape:\")\n",
    "print(f\"   - Type: List[Dict]\")\n",
    "print(f\"   - Each dict contains:\")\n",
    "print(f\"     â€¢ patient_id: str\")\n",
    "print(f\"     â€¢ visit_codes: List[List[int]] shape [num_visits, max_codes_per_visit]\")\n",
    "print(f\"     â€¢ visit_mask: List[List[int]] shape [num_visits, max_codes_per_visit]\")\n",
    "print(f\"     â€¢ sequence_mask: List[int] shape [num_visits]\")\n",
    "print(f\"     â€¢ time_deltas: List[float] shape [num_visits-1]\")\n",
    "print(f\"     â€¢ label: int (0 or 1)\")\n",
    "\n",
    "# Label distribution\n",
    "num_positive = sum(item['label'] for item in dataset_items)\n",
    "num_negative = len(dataset_items) - num_positive\n",
    "\n",
    "print(f\"\\nLabel Distribution:\")\n",
    "print(f\"   Positive (has diabetes): {num_positive} ({num_positive/len(dataset_items)*100:.1f}%)\")\n",
    "print(f\"   Negative (no diabetes): {num_negative} ({num_negative/len(dataset_items)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Create Batched Tensors for LSTM\n",
    "\n",
    "Convert to PyTorch tensors and demonstrate batching with proper padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function (same as in train_lstm_baseline.py)\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for DataLoader.\n",
    "    Handles variable-length sequences and creates proper masks.\n",
    "    \"\"\"\n",
    "    # Extract data\n",
    "    visit_codes = [item['visit_codes'] for item in batch]\n",
    "    labels = torch.tensor([item['label'] for item in batch], dtype=torch.float32)\n",
    "    \n",
    "    # Get dimensions\n",
    "    batch_size = len(visit_codes)\n",
    "    max_visits = max(len(seq) for seq in visit_codes)\n",
    "    max_codes = max(max(len(visit) for visit in seq) for seq in visit_codes)\n",
    "    \n",
    "    # Create padded tensors\n",
    "    padded_codes = torch.zeros(batch_size, max_visits, max_codes, dtype=torch.long)\n",
    "    visit_mask = torch.zeros(batch_size, max_visits, max_codes, dtype=torch.bool)\n",
    "    sequence_mask = torch.zeros(batch_size, max_visits, dtype=torch.bool)\n",
    "    \n",
    "    # Fill tensors\n",
    "    for i, seq in enumerate(visit_codes):\n",
    "        sequence_mask[i, :len(seq)] = 1\n",
    "        for j, visit in enumerate(seq):\n",
    "            padded_codes[i, j, :len(visit)] = torch.tensor(visit)\n",
    "            visit_mask[i, j, :len(visit)] = 1\n",
    "    \n",
    "    return {\n",
    "        'visit_codes': padded_codes,\n",
    "        'visit_mask': visit_mask,\n",
    "        'sequence_mask': sequence_mask,\n",
    "        'labels': labels.unsqueeze(1)\n",
    "    }\n",
    "\n",
    "print(\"âœ… Collate function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample batch\n",
    "batch_size = 4\n",
    "sample_batch = dataset_items[:batch_size]\n",
    "\n",
    "# Collate the batch\n",
    "batched_data = collate_fn(sample_batch)\n",
    "\n",
    "print(\"Sample Batch (LSTM Model Input):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"\\nðŸ“Š Tensor Shapes:\")\n",
    "print(f\"\\n   visit_codes: {batched_data['visit_codes'].shape}\")\n",
    "print(f\"      â†’ [batch_size={batched_data['visit_codes'].shape[0]}, \")\n",
    "print(f\"         max_visits={batched_data['visit_codes'].shape[1]}, \")\n",
    "print(f\"         max_codes_per_visit={batched_data['visit_codes'].shape[2]}]\")\n",
    "print(f\"      â†’ dtype: {batched_data['visit_codes'].dtype}\")\n",
    "print(f\"\\n   visit_mask: {batched_data['visit_mask'].shape}\")\n",
    "print(f\"      â†’ [batch_size, max_visits, max_codes_per_visit]\")\n",
    "print(f\"      â†’ dtype: {batched_data['visit_mask'].dtype}\")\n",
    "print(f\"\\n   sequence_mask: {batched_data['sequence_mask'].shape}\")\n",
    "print(f\"      â†’ [batch_size, max_visits]\")\n",
    "print(f\"      â†’ dtype: {batched_data['sequence_mask'].dtype}\")\n",
    "print(f\"\\n   labels: {batched_data['labels'].shape}\")\n",
    "print(f\"      â†’ [batch_size, 1]\")\n",
    "print(f\"      â†’ dtype: {batched_data['labels'].dtype}\")\n",
    "\n",
    "print(f\"\\n\\nMemory footprint:\")\n",
    "print(f\"   visit_codes: {batched_data['visit_codes'].numel() * 8 / 1024:.2f} KB\")\n",
    "print(f\"   visit_mask: {batched_data['visit_mask'].numel() / 1024:.2f} KB\")\n",
    "print(f\"   sequence_mask: {batched_data['sequence_mask'].numel() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize batch structure for first patient\n",
    "print(\"First Patient in Batch - Detailed View:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "patient_0_codes = batched_data['visit_codes'][0]\n",
    "patient_0_visit_mask = batched_data['visit_mask'][0]\n",
    "patient_0_seq_mask = batched_data['sequence_mask'][0]\n",
    "patient_0_label = batched_data['labels'][0]\n",
    "\n",
    "# Count real visits\n",
    "num_real_visits = patient_0_seq_mask.sum().item()\n",
    "print(f\"Number of real visits: {num_real_visits}\")\n",
    "print(f\"Label: {patient_0_label.item()} ({'Diabetes' if patient_0_label.item() == 1 else 'No Diabetes'})\")\n",
    "\n",
    "# Show first visit details\n",
    "print(f\"\\nFirst visit:\")\n",
    "first_visit_codes = patient_0_codes[0]\n",
    "first_visit_mask = patient_0_visit_mask[0]\n",
    "num_real_codes = first_visit_mask.sum().item()\n",
    "print(f\"   Real codes: {num_real_codes}\")\n",
    "print(f\"   Code IDs (first 10): {first_visit_codes[:10].tolist()}\")\n",
    "print(f\"   Mask (first 10): {first_visit_mask[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Create LSTM Model and Test Forward Pass\n",
    "\n",
    "Instantiate the LSTM baseline model and run a forward pass to verify shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "model = create_lstm_baseline(\n",
    "    vocab_size=len(vocab),\n",
    "    task='binary_classification',\n",
    "    model_size='small'\n",
    ")\n",
    "\n",
    "print(\"LSTM Baseline Model:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(f\"Embedding dim: 128\")\n",
    "print(f\"Hidden dim: 256\")\n",
    "print(f\"Number of layers: 1\")\n",
    "print(f\"Task: Binary classification\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(\n",
    "        visit_codes=batched_data['visit_codes'],\n",
    "        visit_mask=batched_data['visit_mask'],\n",
    "        sequence_mask=batched_data['sequence_mask'],\n",
    "        return_hidden=True\n",
    "    )\n",
    "\n",
    "print(\"Model Output:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nðŸ“Š Output Shapes:\")\n",
    "print(f\"\\n   logits: {output['logits'].shape}\")\n",
    "print(f\"      â†’ [batch_size={output['logits'].shape[0]}, output_dim={output['logits'].shape[1]}]\")\n",
    "print(f\"      â†’ Raw predictions before sigmoid\")\n",
    "print(f\"\\n   predictions: {output['predictions'].shape}\")\n",
    "print(f\"      â†’ [batch_size={output['predictions'].shape[0]}, output_dim={output['predictions'].shape[1]}]\")\n",
    "print(f\"      â†’ After sigmoid activation (probabilities)\")\n",
    "print(f\"\\n   hidden_states: {output['hidden_states'].shape}\")\n",
    "print(f\"      â†’ [batch_size={output['hidden_states'].shape[0]}, \")\n",
    "print(f\"         num_visits={output['hidden_states'].shape[1]}, \")\n",
    "print(f\"         hidden_dim={output['hidden_states'].shape[2]}]\")\n",
    "print(f\"      â†’ LSTM hidden states for each visit\")\n",
    "\n",
    "print(f\"\\n\\nPredictions:\")\n",
    "for i in range(batch_size):\n",
    "    prob = output['predictions'][i, 0].item()\n",
    "    true_label = batched_data['labels'][i, 0].item()\n",
    "    print(f\"   Patient {i+1}: P(diabetes) = {prob:.4f}, True label = {int(true_label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Summary: Complete Data Flow\n",
    "\n",
    "Let's visualize the complete transformation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete Data Transformation Pipeline:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. Raw Synthea CSV Files\")\n",
    "print(\"   â””â”€> patients.csv, encounters.csv, conditions.csv, etc.\")\n",
    "print(\"\\n2. SyntheaAdapter.load_events()\")\n",
    "print(\"   â””â”€> List[MedicalEvent]\")\n",
    "print(\"       â€¢ Each event has: patient_id, timestamp, code, code_type\")\n",
    "print(\"\\n3. VisitGrouper.group_events()\")\n",
    "print(\"   â””â”€> Dict[str, List[Visit]]\")\n",
    "print(\"       â€¢ Key: patient_id\")\n",
    "print(\"       â€¢ Value: List of Visit objects\")\n",
    "print(\"       â€¢ Each Visit has: visit_id, timestamp, codes_by_type\")\n",
    "print(\"\\n4. PatientSequenceBuilder.build_sequences()\")\n",
    "print(\"   â””â”€> List[PatientSequence]\")\n",
    "print(\"       â€¢ Each sequence has: patient_id, visits, sequence_length\")\n",
    "print(\"\\n5. PatientSequenceBuilder.encode_sequence()\")\n",
    "print(\"   â””â”€> Dict with:\")\n",
    "print(\"       â€¢ visit_codes: List[List[int]] - [num_visits, max_codes_per_visit]\")\n",
    "print(\"       â€¢ visit_mask: List[List[int]] - [num_visits, max_codes_per_visit]\")\n",
    "print(\"       â€¢ sequence_mask: List[int] - [num_visits]\")\n",
    "print(\"\\n6. Add Labels\")\n",
    "print(\"   â””â”€> List[Dict] with encoded data + label\")\n",
    "print(\"       â€¢ label: int (0 or 1 for binary classification)\")\n",
    "print(\"\\n7. collate_fn() - Batch Creation\")\n",
    "print(\"   â””â”€> Dict with PyTorch tensors:\")\n",
    "print(\"       â€¢ visit_codes: [batch_size, max_visits, max_codes_per_visit]\")\n",
    "print(\"       â€¢ visit_mask: [batch_size, max_visits, max_codes_per_visit]\")\n",
    "print(\"       â€¢ sequence_mask: [batch_size, max_visits]\")\n",
    "print(\"       â€¢ labels: [batch_size, 1]\")\n",
    "print(\"\\n8. LSTM Model Forward Pass\")\n",
    "print(\"   â””â”€> Dict with:\")\n",
    "print(\"       â€¢ logits: [batch_size, 1] - Raw predictions\")\n",
    "print(\"       â€¢ predictions: [batch_size, 1] - Probabilities (after sigmoid)\")\n",
    "print(\"       â€¢ hidden_states: [batch_size, max_visits, hidden_dim]\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visual diagram\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.axis('off')\n",
    "\n",
    "# Define stages\n",
    "stages = [\n",
    "    (\"Raw Data\\n(CSV Files)\", \"patients.csv\\nencounters.csv\\nconditions.csv\\nobservations.csv\"),\n",
    "    (\"Medical Events\\n(List[MedicalEvent])\", f\"{sum(len(adapter.load_events([pid])) for pid in patient_ids[:5])} events\\n(sample)\"),\n",
    "    (\"Visit Groups\\n(Dict[str, List[Visit]])\", f\"{len(patient_visits)} patients\\n{sum(len(v) for v in patient_visits.values())} visits\"),\n",
    "    (\"Patient Sequences\\n(List[PatientSequence])\", f\"{len(sequences)} sequences\\nmin_visits â‰¥ 2\"),\n",
    "    (\"Encoded Sequences\\n(List[Dict])\", f\"{len(dataset_items)} items\\nwith labels\"),\n",
    "    (\"Batched Tensors\\n(PyTorch)\", f\"[{batch_size}, {batched_data['visit_codes'].shape[1]}, {batched_data['visit_codes'].shape[2]}]\"),\n",
    "    (\"Model Output\\n(Predictions)\", f\"[{batch_size}, 1]\\nprobabilities\")\n",
    "]\n",
    "\n",
    "y_positions = np.linspace(0.9, 0.1, len(stages))\n",
    "\n",
    "for i, ((title, desc), y) in enumerate(zip(stages, y_positions)):\n",
    "    # Draw box\n",
    "    box = plt.Rectangle((0.2, y-0.05), 0.6, 0.08, \n",
    "                        facecolor='lightblue', edgecolor='black', linewidth=2)\n",
    "    ax.add_patch(box)\n",
    "    \n",
    "    # Add text\n",
    "    ax.text(0.5, y+0.02, title, ha='center', va='center', \n",
    "           fontsize=12, fontweight='bold')\n",
    "    ax.text(0.5, y-0.02, desc, ha='center', va='center', \n",
    "           fontsize=9, style='italic')\n",
    "    \n",
    "    # Draw arrow to next stage\n",
    "    if i < len(stages) - 1:\n",
    "        ax.arrow(0.5, y-0.05, 0, -0.04, head_width=0.03, head_length=0.01,\n",
    "                fc='black', ec='black', linewidth=2)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.title('EHR Data Transformation Pipeline for LSTM', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Pipeline visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete pipeline for preparing EHR sequences for the LSTM baseline model:\n",
    "\n",
    "1. âœ… **Loaded and grouped** raw Synthea data into visits\n",
    "2. âœ… **Built patient sequences** with vocabulary\n",
    "3. âœ… **Encoded sequences** to integer IDs with padding/masking\n",
    "4. âœ… **Created labels** for diabetes prediction task\n",
    "5. âœ… **Batched data** into PyTorch tensors\n",
    "6. âœ… **Ran model forward pass** to verify shapes\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Visit-level representation**: Codes within each visit are aggregated (mean/sum/attention)\n",
    "- **Sequence-level modeling**: LSTM captures temporal dependencies across visits\n",
    "- **Proper masking**: Essential for handling variable-length sequences\n",
    "- **Shape transformations**: From raw CSV â†’ tensors â†’ predictions\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- See `data_shape_transformations.md` for detailed shape documentation\n",
    "- See `examples/train_lstm_baseline.py` for full training script\n",
    "- Experiment with different prediction tasks (readmission, mortality, etc.)\n",
    "- Try different model configurations (attention, bidirectional LSTM, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
